{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AKULA\\anaconda3\\envs\\inf\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек из Flask\n",
    "from flask import Flask # Фреймворк Flask для веб-приложений\n",
    "from flask import render_template # Функция для рендеринга HTML-шаблонов\n",
    "# Импорт библиотек для обработки данных и визуализации\n",
    "import json # Библиотека для работы с JSON-данными\n",
    "import pandas as pd # Библиотека для манипуляции и анализа данных\n",
    "#Импорт Plotly для создания интерактивных графиков\n",
    "import plotly # Основная библиотека Plotly\n",
    "import plotly.express as px # Высокоуровневый интерфейс для визуализаций Plotly\n",
    "import plotly.graph_objects as go # Низкоуровневый интерфейс для визуализаций Plotly\n",
    "#Импорт клиента InfluxDB для взаимодействия с базой данных InfluxDB\n",
    "import influxdb_client # Клиентская библиотека для InfluxDB\n",
    "#Определение констант для подключения к InfluxDB\n",
    "# Параметры для подключения к InfluxDB\n",
    "from influxdb_client import InfluxDBClient, Point, WriteOptions \n",
    "from influxdb_client import InfluxDBClient\n",
    "\n",
    "# Параметры для подключения к InfluxDB\n",
    "bucket = \"ebu\"\n",
    "org = \"AKULA1\"\n",
    "token = \"XDBtANrCelRK0vXOYd0yTkMDF2YPZsM_i2Y88ZUmSWIZXMTkoDRtYCMgfAb3D6icLsVegYVeVCwhNYGmnQdQvg==\"\n",
    "url = \"http://localhost:8086\"\n",
    "\n",
    "\n",
    "# Создаем клиент для подключения к InfluxDB\n",
    "client = InfluxDBClient(url=url, token=token, org=org)\n",
    "\n",
    "# Инициализация приложения Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Определение маршрута для главной страницы\n",
    "@app.route(\"/\")\n",
    "def render_results():\n",
    "    try:\n",
    "        # Получение имен колонок и данных метрик\n",
    "        columns_names, data_metrics = metrics_data()\n",
    "\n",
    "        # Генерация JSON для столбчатого графика\n",
    "        graph_metrics_JSON = bar_graph_JSON()\n",
    "\n",
    "        # Генерация JSON для линейного графика\n",
    "        graph_prediction_JSON = line_graph_JSON()\n",
    "\n",
    "        # Рендеринг шаблона index.html с сгенерированными данными\n",
    "        return render_template('index.html',\n",
    "                               graph_prediction_JSON=graph_prediction_JSON,\n",
    "                               graph_metrics_JSON=graph_metrics_JSON,\n",
    "                               data_metrics=data_metrics,\n",
    "                               columns_names=columns_names)\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "# Функция для генерации JSON для линейного графика\n",
    "def line_graph_JSON():\n",
    "    try:\n",
    "        # Чтение запроса Flux из файла\n",
    "        query = open('reqwest.flux').read()\n",
    "        # Выполнение запроса и получение таблиц\n",
    "        tables = query_api.query(query, org=org)\n",
    "        # Инициализация списков для хранения имен колонок и значений индексов\n",
    "        columns = []\n",
    "        for table in tables:\n",
    "            # Извлечение первого имени поля из записей\n",
    "            columns.append(table.records[0].values.get(\"_field\"))\n",
    "\n",
    "        indexes = []  # Список для хранения значений индексов (временных меток)\n",
    "        for table in tables:\n",
    "            for record in table.records:\n",
    "                indexes.append(record.get_time())  # Получение временной метки\n",
    "            break  # Выход после обработки первой таблицы\n",
    "\n",
    "        # Создание DataFrame для хранения данных из InfluxDB\n",
    "        infl_data_df = pd.DataFrame(columns=columns, index=indexes)\n",
    "        # Заполнение DataFrame данными из записей\n",
    "        for table in tables:\n",
    "            data = []\n",
    "            for record in table.records:\n",
    "                data.append(record.get_value())  # Получение значения для каждой записи\n",
    "\n",
    "            # Присвоение данных соответствующему столбцу в DataFrame\n",
    "            infl_data_df[record.values.get(\"_field\")] = data\n",
    "\n",
    "        # Закрытие соединения с клиентом InfluxDB\n",
    "        client.close()\n",
    "        # Назначение имени индекса DataFrame\n",
    "        infl_data_df.index.name = 'time'\n",
    "        # Создание линейного графика с использованием Plotly\n",
    "        fig_line_plot = px.line(infl_data_df)\n",
    "        # Обновление макета линейного графика\n",
    "        fig_line_plot.update_layout(\n",
    "            autosize=False,  # Отключение автоматического изменения размера\n",
    "            width=900,  # Установка ширины графика\n",
    "            height=500  # Установка высоты графика\n",
    "        )\n",
    "        # Преобразование графика в формат JSON для рендеринга\n",
    "        graph_prediction_JSON = json.dumps(fig_line_plot, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "\n",
    "        # Возвращение JSON-представления линейного графика\n",
    "        return graph_prediction_JSON\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error generating line graph JSON: {str(e)}\")\n",
    "\n",
    "# Функция для генерации JSON для столбчатого графика\n",
    "def bar_graph_JSON():\n",
    "    try:\n",
    "        # Получение данных метрик\n",
    "        _, data_metrics = metrics_data()\n",
    "\n",
    "        # Проверка наличия столбца 'R2'\n",
    "        if 'R2' not in data_metrics.columns:\n",
    "            raise KeyError(\"Столбец 'R2' отсутствует в данных метрик.\")\n",
    "\n",
    "        # Создание столбчатого графика для MAE (средней абсолютной ошибки)\n",
    "        fig_bar_plot = px.bar(data_metrics, y='MAE')\n",
    "\n",
    "        # Добавление вторичного графика для значений R2\n",
    "        fig_bar_plot.add_trace(go.Bar(x=data_metrics.index, y=data_metrics['R2'],\n",
    "                                      name='Secondary Value', yaxis='y2'))\n",
    "\n",
    "        # Обновление макета столбчатого графика\n",
    "        fig_bar_plot.update_layout(\n",
    "            autosize=False,  # Отключение автоматического изменения размера\n",
    "            width=500,  # Установка ширины графика\n",
    "            height=500,  # Установка высоты графика\n",
    "            yaxis=dict(title='MAE'),  # Заголовок для основного y-оси\n",
    "            yaxis2=dict(title='R2', overlaying='y', side='right'),  # Заголовок для вторичной у-оси\n",
    "            barmode='group'  # Группировка столбцов\n",
    "        )\n",
    "\n",
    "        # Преобразование графика в формат JSON для рендеринга\n",
    "        graph_metrics_JSON = json.dumps(fig_bar_plot, cls=plotly.utils.PlotlyJSONEncoder)\n",
    "\n",
    "        # Возвращение JSON-представления столбчатого графика\n",
    "        return graph_metrics_JSON\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error generating bar graph JSON: {str(e)}\")\n",
    "\n",
    "# Функция для получения данных метрик из CSV-файла\n",
    "def metrics_data():\n",
    "    try:\n",
    "        # Чтение CSV-файла в DataFrame\n",
    "        data_metrics = pd.read_csv('data.csv', header=0, index_col='Model')\n",
    "        # Извлечение имен колонок из DataFrame\n",
    "        columns_names = data_metrics.columns\n",
    "        # Преобразование всех данных в DataFrame в тип float\n",
    "        data_metrics = data_metrics.astype(float)\n",
    "        # Возвращение имен колонок и данных метрик\n",
    "        return columns_names, data_metrics\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading metrics data: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import influxdb_client\n",
    "client = influxdb_client.InfluxDBClient(\n",
    "    url=url,\n",
    "    token=token,\n",
    "    org=org\n",
    ")\n",
    "query_api = client.query_api()\n",
    "# Составляем запрос на получение из БД\n",
    "# значений сенсора с ID = 1, по всем\n",
    "# имеющимся временным меткам\n",
    "query = \"\"\"from(bucket: \"ebu\")\n",
    " |> range(start: 0 )\n",
    " |> filter(fn: (r) => r[\"_measurement\"] == \"sensors_data\")\n",
    " |> filter(fn: (r) => r[\"sensorid\"] == \"10\")\n",
    "  \"\"\"\n",
    "tables = query_api.query(query, org=\"AKULA1\")\n",
    "# print(tables)\n",
    "# При помощи цикла запишем возвращаемые строки\n",
    "# в лист data\n",
    "data = []\n",
    "for table in tables:\n",
    "  for record in table.records:\n",
    "    # print(record)\n",
    "    data.append({'timestamp': record.get_time(),\n",
    "                 'value': record.get_value()})\n",
    "client.close()\n",
    "# Преобразуем лист в датафрейм\n",
    "df = pd.DataFrame(data)\n",
    "# На основе временных меток сформируем\n",
    "# временные признаки\n",
    "df['minute'] = df['timestamp'].dt.minute.astype('int64')\n",
    "df['hour'] = df['timestamp'].dt.hour.astype('int64')\n",
    "df['second'] = df['timestamp'].dt.second.astype('int64')\n",
    "# На основе целевой колонки сформируем\n",
    "# дополнитлеьный сдвиговый признак\n",
    "df['shift_5'] = df['value'].shift(5)\n",
    "df.index = pd.DatetimeIndex(df['timestamp'])\n",
    "df = df.drop(['timestamp'], axis=1)\n",
    "df.index.sort_values()\n",
    "# df['value'].plot()\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>minute</th>\n",
       "      <th>hour</th>\n",
       "      <th>second</th>\n",
       "      <th>shift_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-04-18 00:00:05+00:00</th>\n",
       "      <td>80.298698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21.799012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-18 00:00:06+00:00</th>\n",
       "      <td>66.404557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16.546189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-18 00:00:07+00:00</th>\n",
       "      <td>19.838376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.998126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-18 00:00:08+00:00</th>\n",
       "      <td>40.502318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>49.105791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-18 00:00:09+00:00</th>\n",
       "      <td>29.348776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42.702048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-18 00:01:35+00:00</th>\n",
       "      <td>76.953710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>98.045212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-18 00:01:36+00:00</th>\n",
       "      <td>90.675148</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>70.220119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-18 00:01:37+00:00</th>\n",
       "      <td>1.172922</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>86.956022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-18 00:01:38+00:00</th>\n",
       "      <td>21.089706</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>58.949153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-18 00:01:39+00:00</th>\n",
       "      <td>26.615945</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>17.804804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               value  minute  hour  second    shift_5\n",
       "timestamp                                                            \n",
       "2024-04-18 00:00:05+00:00  80.298698       0     0       5  21.799012\n",
       "2024-04-18 00:00:06+00:00  66.404557       0     0       6  16.546189\n",
       "2024-04-18 00:00:07+00:00  19.838376       0     0       7   3.998126\n",
       "2024-04-18 00:00:08+00:00  40.502318       0     0       8  49.105791\n",
       "2024-04-18 00:00:09+00:00  29.348776       0     0       9  42.702048\n",
       "...                              ...     ...   ...     ...        ...\n",
       "2024-04-18 00:01:35+00:00  76.953710       1     0      35  98.045212\n",
       "2024-04-18 00:01:36+00:00  90.675148       1     0      36  70.220119\n",
       "2024-04-18 00:01:37+00:00   1.172922       1     0      37  86.956022\n",
       "2024-04-18 00:01:38+00:00  21.089706       1     0      38  58.949153\n",
       "2024-04-18 00:01:39+00:00  26.615945       1     0      39  17.804804\n",
       "\n",
       "[95 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для подключения к InfluxDB\n",
    "bucket = \"ebu\"\n",
    "org = \"AKULA1\"\n",
    "token = \"XDBtANrCelRK0vXOYd0yTkMDF2YPZsM_i2Y88ZUmSWIZXMTkoDRtYCMgfAb3D6icLsVegYVeVCwhNYGmnQdQvg==\"\n",
    "url = \"http://localhost:8086\"\n",
    "\n",
    "# Создание экземпляра клиента InfluxDB\n",
    "client = influxdb_client.InfluxDBClient(\n",
    "    url=url,\n",
    "    token=token,\n",
    "    org=org\n",
    ")\n",
    "\n",
    "# Создание экземпляра API запросов для выполнения запросов\n",
    "query_api = client.query_api()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Функция для получения данных метрик из InfluxDB\n",
    "def metrics_data():\n",
    "    try:\n",
    "        # Чтение запроса Flux из файла\n",
    "        query = open('reqwest.flux').read()\n",
    "        # Выполнение запроса и получение таблиц\n",
    "        tables = query_api.query(query, org=org)\n",
    "        # Инициализация списков для хранения имен колонок и значений индексов\n",
    "        columns = []\n",
    "        for table in tables:\n",
    "            # Извлечение первого имени поля из записей\n",
    "            columns.append(table.records[0].values.get(\"_field\"))\n",
    "\n",
    "        indexes = []  # Список для хранения значений индексов (временных меток)\n",
    "        for table in tables:\n",
    "            for record in table.records:\n",
    "                indexes.append(record.get_time())  # Получение временной метки\n",
    "            break  # Выход после обработки первой таблицы\n",
    "\n",
    "        # Создание DataFrame для хранения данных из InfluxDB\n",
    "        infl_data_df = pd.DataFrame(columns=columns, index=indexes)\n",
    "        # Заполнение DataFrame данными из записей\n",
    "        for table in tables:\n",
    "            data = []\n",
    "            for record in table.records:\n",
    "                data.append(record.get_value())  # Получение значения для каждой записи\n",
    "\n",
    "            # Присвоение данных соответствующему столбцу в DataFrame\n",
    "            infl_data_df[record.values.get(\"_field\")] = data\n",
    "\n",
    "        # Закрытие соединения с клиентом InfluxDB\n",
    "        client.close()\n",
    "        # Назначение имени индекса DataFrame\n",
    "        infl_data_df.index.name = 'time'\n",
    "        # Преобразование DataFrame в формат, пригодный для метрик\n",
    "        infl_data_df = infl_data_df.T  # Транспонирование DataFrame\n",
    "        infl_data_df.columns = columns  # Установка имен колонок\n",
    "        # Возвращение имен колонок и данных метрик\n",
    "        return columns, infl_data_df\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading metrics data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " Empty DataFrame\n",
       " Columns: []\n",
       " Index: [])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from(bucket: \"ebu\")\n",
      "  |> range(start: 2024-04-18T00:00:00Z, stop: 2024-04-18T00:02:00Z)\n",
      "  |> filter(fn: (r) => r[\"_measurement\"] == \"sensors_data_prediction\")\n",
      "  |> filter(fn: (r) => r[\"SensorID\"] == \"10\")\n",
      "  |> yield(name: \"mean\")\n",
      "\n",
      "FluxRecord() table: 0, {'result': 'mean', 'table': 0, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 35, tzinfo=datetime.timezone.utc), '_value': 40.759470702346675, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.77126796194519', 'r2': '-0.16506433597301462'}\n",
      "FluxRecord() table: 0, {'result': 'mean', 'table': 0, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 36, tzinfo=datetime.timezone.utc), '_value': 47.53598285011579, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.77126796194519', 'r2': '-0.16506433597301462'}\n",
      "FluxRecord() table: 0, {'result': 'mean', 'table': 0, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 37, tzinfo=datetime.timezone.utc), '_value': 43.222203558864, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.77126796194519', 'r2': '-0.16506433597301462'}\n",
      "FluxRecord() table: 0, {'result': 'mean', 'table': 0, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 38, tzinfo=datetime.timezone.utc), '_value': 50.04395575387543, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.77126796194519', 'r2': '-0.16506433597301462'}\n",
      "FluxRecord() table: 0, {'result': 'mean', 'table': 0, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 39, tzinfo=datetime.timezone.utc), '_value': 60.135349346253136, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.77126796194519', 'r2': '-0.16506433597301462'}\n",
      "FluxRecord() table: 1, {'result': 'mean', 'table': 1, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 35, tzinfo=datetime.timezone.utc), '_value': 40.79335023529414, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.788588316971136', 'r2': '-0.1658958706143845'}\n",
      "FluxRecord() table: 1, {'result': 'mean', 'table': 1, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 36, tzinfo=datetime.timezone.utc), '_value': 47.583270991660875, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.788588316971136', 'r2': '-0.1658958706143845'}\n",
      "FluxRecord() table: 1, {'result': 'mean', 'table': 1, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 37, tzinfo=datetime.timezone.utc), '_value': 43.26264490637918, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.788588316971136', 'r2': '-0.1658958706143845'}\n",
      "FluxRecord() table: 1, {'result': 'mean', 'table': 1, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 38, tzinfo=datetime.timezone.utc), '_value': 50.097888336795364, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.788588316971136', 'r2': '-0.1658958706143845'}\n",
      "FluxRecord() table: 1, {'result': 'mean', 'table': 1, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 39, tzinfo=datetime.timezone.utc), '_value': 60.208744865440266, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.788588316971136', 'r2': '-0.1658958706143845'}\n",
      "FluxRecord() table: 2, {'result': 'mean', 'table': 2, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 35, tzinfo=datetime.timezone.utc), '_value': 40.82800761933061, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.7968028531389', 'r2': '-0.16626404086958102'}\n",
      "FluxRecord() table: 2, {'result': 'mean', 'table': 2, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 36, tzinfo=datetime.timezone.utc), '_value': 47.619011014449484, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.7968028531389', 'r2': '-0.16626404086958102'}\n",
      "FluxRecord() table: 2, {'result': 'mean', 'table': 2, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 37, tzinfo=datetime.timezone.utc), '_value': 43.29863360524014, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.7968028531389', 'r2': '-0.16626404086958102'}\n",
      "FluxRecord() table: 2, {'result': 'mean', 'table': 2, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 38, tzinfo=datetime.timezone.utc), '_value': 50.13496307634891, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.7968028531389', 'r2': '-0.16626404086958102'}\n",
      "FluxRecord() table: 2, {'result': 'mean', 'table': 2, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 39, tzinfo=datetime.timezone.utc), '_value': 60.24715151468964, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.7968028531389', 'r2': '-0.16626404086958102'}\n",
      "FluxRecord() table: 3, {'result': 'mean', 'table': 3, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 35, tzinfo=datetime.timezone.utc), '_value': 40.88453394001678, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.80731442981572', 'r2': '-0.1667158135026383'}\n",
      "FluxRecord() table: 3, {'result': 'mean', 'table': 3, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 36, tzinfo=datetime.timezone.utc), '_value': 47.6743397818338, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.80731442981572', 'r2': '-0.1667158135026383'}\n",
      "FluxRecord() table: 3, {'result': 'mean', 'table': 3, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 37, tzinfo=datetime.timezone.utc), '_value': 43.354848781358555, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.80731442981572', 'r2': '-0.1667158135026383'}\n",
      "FluxRecord() table: 3, {'result': 'mean', 'table': 3, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 38, tzinfo=datetime.timezone.utc), '_value': 50.18997219816786, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.80731442981572', 'r2': '-0.1667158135026383'}\n",
      "FluxRecord() table: 3, {'result': 'mean', 'table': 3, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 39, tzinfo=datetime.timezone.utc), '_value': 60.30034018820689, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.80731442981572', 'r2': '-0.1667158135026383'}\n",
      "FluxRecord() table: 4, {'result': 'mean', 'table': 4, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 35, tzinfo=datetime.timezone.utc), '_value': 40.9230050641763, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.81348281887398', 'r2': '-0.16696448705477773'}\n",
      "FluxRecord() table: 4, {'result': 'mean', 'table': 4, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 36, tzinfo=datetime.timezone.utc), '_value': 47.712532463356474, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.81348281887398', 'r2': '-0.16696448705477773'}\n",
      "FluxRecord() table: 4, {'result': 'mean', 'table': 4, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 37, tzinfo=datetime.timezone.utc), '_value': 43.390757170299636, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.81348281887398', 'r2': '-0.16696448705477773'}\n",
      "FluxRecord() table: 4, {'result': 'mean', 'table': 4, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 38, tzinfo=datetime.timezone.utc), '_value': 50.225610326831124, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.81348281887398', 'r2': '-0.16696448705477773'}\n",
      "FluxRecord() table: 4, {'result': 'mean', 'table': 4, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 39, tzinfo=datetime.timezone.utc), '_value': 60.336299421576044, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.81348281887398', 'r2': '-0.16696448705477773'}\n",
      "FluxRecord() table: 5, {'result': 'mean', 'table': 5, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 35, tzinfo=datetime.timezone.utc), '_value': 40.85560984916518, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.813594024926815', 'r2': '-0.1670933500603975'}\n",
      "FluxRecord() table: 5, {'result': 'mean', 'table': 5, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 36, tzinfo=datetime.timezone.utc), '_value': 47.65970318417219, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.813594024926815', 'r2': '-0.1670933500603975'}\n",
      "FluxRecord() table: 5, {'result': 'mean', 'table': 5, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 37, tzinfo=datetime.timezone.utc), '_value': 43.33445547355878, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.813594024926815', 'r2': '-0.1670933500603975'}\n",
      "FluxRecord() table: 5, {'result': 'mean', 'table': 5, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 38, tzinfo=datetime.timezone.utc), '_value': 50.18394814883092, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.813594024926815', 'r2': '-0.1670933500603975'}\n",
      "FluxRecord() table: 5, {'result': 'mean', 'table': 5, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 39, tzinfo=datetime.timezone.utc), '_value': 60.31459483238589, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.813594024926815', 'r2': '-0.1670933500603975'}\n",
      "FluxRecord() table: 6, {'result': 'mean', 'table': 6, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 35, tzinfo=datetime.timezone.utc), '_value': 40.836283, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.820126', 'r2': '-0.16744'}\n",
      "FluxRecord() table: 7, {'result': 'mean', 'table': 7, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 35, tzinfo=datetime.timezone.utc), '_value': 40.83628282362131, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.820126437450824', 'r2': '-0.16743987466352706'}\n",
      "FluxRecord() table: 7, {'result': 'mean', 'table': 7, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 36, tzinfo=datetime.timezone.utc), '_value': 47.65740476270149, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.820126437450824', 'r2': '-0.16743987466352706'}\n",
      "FluxRecord() table: 7, {'result': 'mean', 'table': 7, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 37, tzinfo=datetime.timezone.utc), '_value': 43.31790397942164, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.820126437450824', 'r2': '-0.16743987466352706'}\n",
      "FluxRecord() table: 7, {'result': 'mean', 'table': 7, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 38, tzinfo=datetime.timezone.utc), '_value': 50.184552864478796, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.820126437450824', 'r2': '-0.16743987466352706'}\n",
      "FluxRecord() table: 7, {'result': 'mean', 'table': 7, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 39, tzinfo=datetime.timezone.utc), '_value': 60.34157822648061, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.820126437450824', 'r2': '-0.16743987466352706'}\n",
      "FluxRecord() table: 8, {'result': 'mean', 'table': 8, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 35, tzinfo=datetime.timezone.utc), '_value': 40.785593876152674, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.82355842904964', 'r2': '-0.16772385335450046'}\n",
      "FluxRecord() table: 8, {'result': 'mean', 'table': 8, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 36, tzinfo=datetime.timezone.utc), '_value': 47.6201316050584, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.82355842904964', 'r2': '-0.16772385335450046'}\n",
      "FluxRecord() table: 8, {'result': 'mean', 'table': 8, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 37, tzinfo=datetime.timezone.utc), '_value': 43.27938702680962, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.82355842904964', 'r2': '-0.16772385335450046'}\n",
      "FluxRecord() table: 8, {'result': 'mean', 'table': 8, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 38, tzinfo=datetime.timezone.utc), '_value': 50.15951150177172, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.82355842904964', 'r2': '-0.16772385335450046'}\n",
      "FluxRecord() table: 8, {'result': 'mean', 'table': 8, '_start': datetime.datetime(2024, 4, 18, 0, 0, tzinfo=datetime.timezone.utc), '_stop': datetime.datetime(2024, 4, 18, 0, 2, tzinfo=datetime.timezone.utc), '_time': datetime.datetime(2024, 4, 18, 0, 1, 39, tzinfo=datetime.timezone.utc), '_value': 60.33433439468207, 'DataType': 'prediction', 'SensorID': '10', '_field': 'sgd', '_measurement': 'sensors_data_prediction', 'mae': '36.82355842904964', 'r2': '-0.16772385335450046'}\n"
     ]
    }
   ],
   "source": [
    "from influxdb_client import InfluxDBClient\n",
    "\n",
    "# Параметры для подключения к InfluxDB\n",
    "bucket = \"ebu\"\n",
    "org = \"AKULA1\"\n",
    "token = \"XDBtANrCelRK0vXOYd0yTkMDF2YPZsM_i2Y88ZUmSWIZXMTkoDRtYCMgfAb3D6icLsVegYVeVCwhNYGmnQdQvg==\"\n",
    "url = \"http://localhost:8086\"\n",
    "\n",
    "# Создание экземпляра клиента InfluxDB\n",
    "client = InfluxDBClient(\n",
    "    url=url,\n",
    "    token=token,\n",
    "    org=org\n",
    ")\n",
    "\n",
    "# Создание экземпляра API запросов для выполнения запросов\n",
    "query_api = client.query_api()\n",
    "\n",
    "# Чтение запроса Flux из файла\n",
    "with open('reqwest.flux', 'r') as file:\n",
    "    query = file.read()\n",
    "    print(query)\n",
    "# Выполнение запроса и получение таблиц\n",
    "tables = query_api.query(query, org=org)\n",
    "# print(tables)\n",
    "# Вывод данных для проверки\n",
    "for table in tables:\n",
    "    for record in table.records:\n",
    "        print(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error reading metrics data: '_field'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 32\u001b[0m, in \u001b[0;36mmetrics_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mrecords:\n\u001b[1;32m---> 32\u001b[0m     field \u001b[38;5;241m=\u001b[39m \u001b[43mrecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m field \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns:\n",
      "File \u001b[1;32mc:\\Users\\AKULA\\anaconda3\\envs\\inf\\Lib\\site-packages\\influxdb_client\\client\\flux_table.py:124\u001b[0m, in \u001b[0;36mFluxRecord.get_field\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get field name.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_field\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AKULA\\anaconda3\\envs\\inf\\Lib\\site-packages\\influxdb_client\\client\\flux_table.py:132\u001b[0m, in \u001b[0;36mFluxRecord.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get value by key.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: '_field'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError reading metrics data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Вызов функции для проверки\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m columns_names, data_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns:\u001b[39m\u001b[38;5;124m\"\u001b[39m, columns_names)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_metrics)\n",
      "Cell \u001b[1;32mIn[98], line 58\u001b[0m, in \u001b[0;36mmetrics_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m columns, infl_data_df\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError reading metrics data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error reading metrics data: '_field'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from influxdb_client import InfluxDBClient\n",
    "\n",
    "# Параметры для подключения к InfluxDB\n",
    "bucket = \"eee\"\n",
    "org = \"AKULA1\"\n",
    "token = \"XDBtANrCelRK0vXOYd0yTkMDF2YPZsM_i2Y88ZUmSWIZXMTkoDRtYCMgfAb3D6icLsVegYVeVCwhNYGmnQdQvg==\"\n",
    "url = \"http://localhost:8086\"\n",
    "\n",
    "# Создание экземпляра клиента InfluxDB\n",
    "client = InfluxDBClient(\n",
    "    url=url,\n",
    "    token=token,\n",
    "    org=org\n",
    ")\n",
    "\n",
    "# Создание экземпляра API запросов для выполнения запросов\n",
    "query_api = client.query_api()\n",
    "\n",
    "# Функция для получения данных метрик из InfluxDB\n",
    "def metrics_data():\n",
    "    try:\n",
    "        # Чтение запроса Flux из файла\n",
    "        with open('reqwest.flux', 'r') as file:\n",
    "            query = file.read()\n",
    "        # Выполнение запроса и получение таблиц\n",
    "        tables = query_api.query(query, org=org)\n",
    "        # Инициализация списков для хранения имен колонок и значений индексов\n",
    "        columns = []\n",
    "        for table in tables:\n",
    "            for record in table.records:\n",
    "                field = record.get_field()\n",
    "                if field not in columns:\n",
    "                    columns.append(field)\n",
    "\n",
    "        indexes = []  # Список для хранения значений индексов (временных меток)\n",
    "        for table in tables:\n",
    "            for record in table.records:\n",
    "                indexes.append(record.get_time())  # Получение временной метки\n",
    "            break  # Выход после обработки первой таблицы\n",
    "\n",
    "        # Создание DataFrame для хранения данных из InfluxDB\n",
    "        infl_data_df = pd.DataFrame(columns=columns, index=indexes)\n",
    "        # Заполнение DataFrame данными из записей\n",
    "        for table in tables:\n",
    "            for record in table.records:\n",
    "                field = record.get_field()\n",
    "                value = record.get_value()\n",
    "                infl_data_df.at[record.get_time(), field] = value\n",
    "\n",
    "        # Закрытие соединения с клиентом InfluxDB\n",
    "        client.close()\n",
    "        # Назначение имени индекса DataFrame\n",
    "        infl_data_df.index.name = 'time'\n",
    "        # Возвращение имен колонок и данных метрик\n",
    "        return columns, infl_data_df\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading metrics data: {str(e)}\")\n",
    "\n",
    "# Вызов функции для проверки\n",
    "columns_names, data_metrics = metrics_data()\n",
    "print(\"Columns:\", columns_names)\n",
    "print(\"Data Metrics:\", data_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flux Query: \n",
      "        from(bucket: \"eee\")\n",
      "          |> range(start: 2024-04-18T00:00:00Z, stop: 2024-04-18T00:02:00Z)\n",
      "          |> filter(fn: (r) => r[\"_measurement\"] == \"sensors_data_prediction\")\n",
      "          |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
      "        \n",
      "Tables received: [<FluxTable: 11 columns, 5 records>]\n",
      "Columns: ['mae', '_measurement', 'sgd', 'DataType', 'SensorID', 'r2']\n",
      "Data Metrics:                                           mae             _measurement  \\\n",
      "time                                                                     \n",
      "2024-04-18 00:01:35+00:00  36.805871293260054  sensors_data_prediction   \n",
      "2024-04-18 00:01:36+00:00  36.805871293260054  sensors_data_prediction   \n",
      "2024-04-18 00:01:37+00:00  36.805871293260054  sensors_data_prediction   \n",
      "2024-04-18 00:01:38+00:00  36.805871293260054  sensors_data_prediction   \n",
      "2024-04-18 00:01:39+00:00  36.805871293260054  sensors_data_prediction   \n",
      "\n",
      "                                 sgd    DataType SensorID                   r2  \n",
      "time                                                                            \n",
      "2024-04-18 00:01:35+00:00   40.82622  prediction       10  -0.1667362773573997  \n",
      "2024-04-18 00:01:36+00:00  47.628987  prediction       10  -0.1667362773573997  \n",
      "2024-04-18 00:01:37+00:00  43.302929  prediction       10  -0.1667362773573997  \n",
      "2024-04-18 00:01:38+00:00  50.151092  prediction       10  -0.1667362773573997  \n",
      "2024-04-18 00:01:39+00:00  60.280258  prediction       10  -0.1667362773573997  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from influxdb_client import InfluxDBClient\n",
    "\n",
    "# Параметры для подключения к InfluxDB\n",
    "bucket = \"eee\"\n",
    "org = \"AKULA1\"\n",
    "token = \"XDBtANrCelRK0vXOYd0yTkMDF2YPZsM_i2Y88ZUmSWIZXMTkoDRtYCMgfAb3D6icLsVegYVeVCwhNYGmnQdQvg==\"\n",
    "url = \"http://localhost:8086\"\n",
    "\n",
    "# Создание экземпляра клиента InfluxDB\n",
    "client = InfluxDBClient(\n",
    "    url=url,\n",
    "    token=token,\n",
    "    org=org\n",
    ")\n",
    "\n",
    "# Создание экземпляра API запросов для выполнения запросов\n",
    "query_api = client.query_api()\n",
    "\n",
    "# Функция для получения данных метрик из InfluxDB\n",
    "def metrics_data():\n",
    "    try:\n",
    "        # Flux запрос для извлечения данных\n",
    "        query = \"\"\"\n",
    "        from(bucket: \"eee\")\n",
    "          |> range(start: 2024-04-18T00:00:00Z, stop: 2024-04-18T00:02:00Z)\n",
    "          |> filter(fn: (r) => r[\"_measurement\"] == \"sensors_data_prediction\")\n",
    "          |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "        \"\"\"\n",
    "        print(\"Flux Query:\", query)  # Отладочное сообщение\n",
    "\n",
    "        # Выполнение запроса и получение таблиц\n",
    "        tables = query_api.query(query, org=org)\n",
    "        print(\"Tables received:\", tables)  # Отладочное сообщение\n",
    "\n",
    "        # Инициализация списков для хранения имен колонок и значений индексов\n",
    "        columns = set()\n",
    "        for table in tables:\n",
    "            for record in table.records:\n",
    "                for key in record.values.keys():\n",
    "                    if key not in [\"_start\", \"_stop\", \"_time\", \"result\", \"table\"]:\n",
    "                        columns.add(key)\n",
    "\n",
    "        indexes = []  # Список для хранения значений индексов (временных меток)\n",
    "        for table in tables:\n",
    "            for record in table.records:\n",
    "                indexes.append(record.get_time())  # Получение временной метки\n",
    "            break  # Выход после обработки первой таблицы\n",
    "\n",
    "        # Создание DataFrame для хранения данных из InfluxDB\n",
    "        infl_data_df = pd.DataFrame(columns=list(columns), index=pd.to_datetime(indexes))\n",
    "        # Заполнение DataFrame данными из записей\n",
    "        for table in tables:\n",
    "            for record in table.records:\n",
    "                for key in record.values.keys():\n",
    "                    if key not in [\"_start\", \"_stop\", \"_time\", \"result\", \"table\"]:\n",
    "                        infl_data_df.at[record.get_time(), key] = record.values[key]\n",
    "\n",
    "        # Закрытие соединения с клиентом InfluxDB\n",
    "        client.close()\n",
    "        # Назначение имени индекса DataFrame\n",
    "        infl_data_df.index.name = 'time'\n",
    "        # Возвращение имен колонок и данных метрик\n",
    "        return list(columns), infl_data_df\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading metrics data: {str(e)}\")\n",
    "\n",
    "# Вызов функции для проверки\n",
    "columns_names, data_metrics = metrics_data()\n",
    "print(\"Columns:\", columns_names)\n",
    "print(\"Data Metrics:\", data_metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
